{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79d45564",
   "metadata": {},
   "source": [
    "Week 10 Document Classification Assignment\n",
    "By Evan McLaughlin and Vladimir Nimchenko\n",
    "\n",
    "~~~\n",
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data:  UCI Machine Learning Repository: Spambase Data Set\n",
    "\n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "\n",
    "For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.\n",
    "~~~\n",
    "\n",
    "For our assignment, we elected to build a classifier to bucket imdb reviews as either positive or negative. We located a good dataset for this exercise on kaggle, linked below. \n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ef77376c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import random\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e358f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we set the seed and write our function to preprocess the segment data, and employ tokenization and normalization\n",
    "# and pull out the document features\n",
    "random.seed(269)\n",
    "def preprocess_and_segment(text, segment_length):\n",
    "    tokens = text.split()\n",
    "    tokens = [token.lower().strip('.,?!') for token in tokens]\n",
    "    segments = [tokens[i:i + segment_length] for i in range(0, len(tokens), segment_length)]\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "79b6e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(segment, word_features):\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains({})'.format(word)] = (word in segment)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e1a2af97",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# next we write our function to train and test our classifier\n",
    "def train_and_test_classifier(featuresets, train_size):\n",
    "    random.shuffle(featuresets)\n",
    "    train_set, test_set = featuresets[:train_size], featuresets[train_size:]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    accuracy = nltk.classify.accuracy(classifier, test_set)\n",
    "    return classifier, accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344330c2",
   "metadata": {},
   "source": [
    "In the interest of efficiency, the segment_length and word_features_count variables below are used to control the length of text segments and the number of word features extracted for classification. We can set these values where we are comfortable, depending on the specific characteristics of the dataset and the requirements of your classification task. We can thus adjust these values to optimize performance of the model. We can adjust segment lengths or numbers of word features to find the settings that yield the best classification accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "eaff55e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can kick off our code. Let's set our segment length and word features counts at 2000 to begin and read in the data\n",
    "\n",
    "segment_length = 2000\n",
    "word_features_count = 2000\n",
    "url = \"https://raw.githubusercontent.com/evanmclaughlin/DATA-620/main/imdb_reviews.v3.csv\"\n",
    "response = requests.get(url)\n",
    "data = io.StringIO(response.content.decode('utf-8'))\n",
    "imdb_reviews = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "17bc8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We next must preprocess and combine the words for feature extraction\n",
    "\n",
    "all_segments = [(preprocess_and_segment(review, segment_length), label) for review, label in zip(imdb_reviews['review'], imdb_reviews['sentiment'])]\n",
    "all_words = [word.lower() for review in imdb_reviews['review'] for word in review.split()]\n",
    "word_frequencies = nltk.FreqDist(all_words)\n",
    "word_features = list(word_frequencies.keys())[:word_features_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "529c2199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next up, we extract document features for all segments and train-test our classifier, selecting 30% for our training\n",
    "featuresets = []\n",
    "for segment, label in all_segments:\n",
    "    features = document_features(segment, word_features)\n",
    "    featuresets.append((features, label))\n",
    "    \n",
    "train_size = int(len(featuresets) * 0.30) \n",
    "classifier, accuracy = train_and_test_classifier(featuresets, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "10f91e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5087419232231091\n"
     ]
    }
   ],
   "source": [
    "# Let's check out the accuracy\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdde770",
   "metadata": {},
   "source": [
    "This is basically a coin flip and a poor effort to start out with. In order to improve our classifier, we can consider several options, including TF-IDF vectorizer, which captures the significance of terms within individual documents and across the dataset. It weighs words based on their importance and helps prioritize terms that contribute to sentiment while mitigating the impact of common words. This makes TF-IDF a good choice to sentiment analysis where correctly identifying key terms is critical for prediction success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2bcafc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8279379157427937\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# after splitting the data into train-test, we generate a \"pipeline\" with the TF-IDF vectorizer and random forest classifier \n",
    "X_train, X_test, y_train, y_test = train_test_split(imdb_reviews['review'], imdb_reviews['sentiment'], test_size=0.3, random_state=269)\n",
    "pipeline = make_pipeline(TfidfVectorizer(max_features=2000), RandomForestClassifier(n_estimators=100, random_state=269))\n",
    "\n",
    "# Next, we train the model and predict on the test set\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3939582",
   "metadata": {},
   "source": [
    "We've really improved our accuracy using the TF-IDF vectorizer as we are now providing appropriate weight to important words within the document, improving our classifier's discriminitive power enormously. We limited our feature space to the top 2000 most frequent terms, the model focuses on the most informative features, enhancing its ability to generalize to unseen data. Combining TF-IDF with a Random Forest classifier further captures complex relationships within the data to enhance prediction power. Above, we also employed a pipeline which simplifies the workflow, integrating data preprocessing and model training into a single object for enhanced efficiency. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
